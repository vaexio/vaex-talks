{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `vaex` @ PyData Budapest 2020\n",
    "\n",
    "## Machine Learning Example - Predict the duration of taxi trips\n",
    "\n",
    "To find out more details check out\n",
    "[ML impossible: Train 1 billion samples in 5 minutes on your laptop using Vaex and Scikit-Learn](https://towardsdatascience.com/ml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385).\n",
    "\n",
    "Running this notebooks requires `vaex==3.0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:18:57.057875Z",
     "start_time": "2020-06-10T14:18:56.336474Z"
    }
   },
   "outputs": [],
   "source": [
    "import vaex\n",
    "vaex.multithreading.thread_count_default = 8\n",
    "\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial step: reading the data and do a train/test split immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:18:58.870383Z",
     "start_time": "2020-06-10T14:18:58.754960Z"
    }
   },
   "outputs": [],
   "source": [
    "!du -h /data/taxi/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:19:01.688917Z",
     "start_time": "2020-06-10T14:19:01.628637Z"
    }
   },
   "outputs": [],
   "source": [
    "df = vaex.open('/data/taxi/yellow_taxi_2012.hdf5')\n",
    "\n",
    "# Train / test split (by date)\n",
    "df_train, df_test = df.ml.train_test_split(test_size=0.15)\n",
    "\n",
    "print(f'Number of samples in the full dataset: {len(df):,}')\n",
    "print(f'Number of samples in the training set: {len(df_train):,}')\n",
    "print(f'Number of samples in the test set:       {len(df_test):,}')\n",
    "\n",
    "# Check if the lengths of the datasets match\n",
    "assert len(df) == len(df_test) + len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:19:07.320098Z",
     "start_time": "2020-06-10T14:19:07.317093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Time in transit (minutes) - This is the target variable\n",
    "df_train['trip_duration_min'] = (df_train.dropoff_datetime - df_train.pickup_datetime) / \\\n",
    "                                   np.timedelta64(1, 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:19:10.631787Z",
     "start_time": "2020-06-10T14:19:10.628562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Speed (miles per hour) - Used for cleaning of the training data\n",
    "df_train['trip_speed_mph'] = df_train.trip_distance / \\\n",
    "                                ((df_train.dropoff_datetime - df_train.pickup_datetime) / \\\n",
    "                                np.timedelta64(1, 'h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:19:12.137690Z",
     "start_time": "2020-06-10T14:19:12.003053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickup datetime features\n",
    "df_train['pickup_time'] = df_train.pickup_datetime.dt.hour + df_train.pickup_datetime.dt.minute / 60.\n",
    "df_train['pickup_day'] = df_train.pickup_datetime.dt.dayofweek\n",
    "df_train['pickup_is_weekend'] = (df_train.pickup_day>=5).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:19:13.750236Z",
     "start_time": "2020-06-10T14:19:13.267578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Arc distance  in miles\n",
    "def arc_distance(theta_1, phi_1, theta_2, phi_2):\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    distance = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "    return distance * 3958.8\n",
    "\n",
    "# Create the feature\n",
    "df_train['arc_distance'] = arc_distance(df_train.pickup_longitude, \n",
    "                                        df_train.pickup_latitude, \n",
    "                                        df_train.dropoff_longitude, \n",
    "                                        df_train.dropoff_latitude).jit_numba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:19:17.170566Z",
     "start_time": "2020-06-10T14:19:17.131889Z"
    }
   },
   "outputs": [],
   "source": [
    "def direction_angle(theta_1, phi_1, theta_2, phi_2):\n",
    "    dtheta = theta_2 - theta_1\n",
    "    dphi = phi_2 - phi_1\n",
    "    radians = np.arctan2(dtheta, dphi)\n",
    "    return np.rad2deg(radians)\n",
    "\n",
    "# Create the feature\n",
    "df_train['direction_angle'] = direction_angle(df_train.pickup_longitude, \n",
    "                                              df_train.pickup_latitude, \n",
    "                                              df_train.dropoff_longitude, \n",
    "                                              df_train.dropoff_latitude).jit_numba()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:19:23.469820Z",
     "start_time": "2020-06-10T14:19:23.276811Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter abnormal number of passengers\n",
    "df_train = df_train[(df_train.passenger_count>0) & (df_train.passenger_count<7)]\n",
    "\n",
    "# Select taxi trips have travelled maximum 7 miles (but also with non-zero distance).\n",
    "df_train = df_train[(df_train.trip_distance > 0) & (df_train.trip_distance < 7)]\n",
    "\n",
    "# Filter taxi trips that have durations longer than 25 minutes or that lasted less than 3 minutes\n",
    "df_train = df_train[(df_train.trip_duration_min > 3) & (df_train.trip_duration_min < 25)]\n",
    "\n",
    "# Filter out errouneous average trip speeds.\n",
    "df_train = df_train[(df_train.trip_speed_mph > 1) & (df_train.trip_speed_mph < 60)]\n",
    "\n",
    "# Define the NYC boundaries\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90\n",
    "\n",
    "# Make a selection based on the boundaries\n",
    "df_train = df_train[(df_train.pickup_longitude > long_min)  & (df_train.pickup_longitude < long_max) & \\\n",
    "                    (df_train.pickup_latitude > lat_min)    & (df_train.pickup_latitude < lat_max) & \\\n",
    "                    (df_train.dropoff_longitude > long_min) & (df_train.dropoff_longitude < long_max) & \\\n",
    "                    (df_train.dropoff_latitude > lat_min)   & (df_train.dropoff_latitude < lat_max)]\n",
    "\n",
    "# If there are unknown (N/A) pick-up or drop-off locations, choose a representative value. \n",
    "df_train['dropoff_latitude'] = df_train.dropoff_latitude.fillna(value=40.76)\n",
    "df_train['pickup_latitude'] = df_train.pickup_latitude.fillna(value=40.76)\n",
    "\n",
    "df_train['dropoff_longitude'] = df_train.dropoff_longitude.fillna(value=-73.99)\n",
    "df_train['pickup_longitude'] = df_train.pickup_longitude.fillna(value=-73.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `vaex-ml`\n",
    "\n",
    "A `vaex` package for machine learning. \n",
    "\n",
    "Implements various data transformers:\n",
    " - numerical scalers\n",
    " - categorical encoders\n",
    " - PCA transformer\n",
    " - GroupBy transformers\n",
    " - more coming soon\n",
    " \n",
    "Wrappers around other popular model libraries\n",
    " - xgboost / lightgbm / catboost\n",
    " - scikit-learn\n",
    " - tensorflow / keras (coming soon!)\n",
    " \n",
    "[We are working on better integration between scikit-learn and vaex](https://github.com/scikit-learn/scikit-learn/pull/14963).\n",
    "\n",
    "scikit-learn PR #14963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:20:04.684112Z",
     "start_time": "2020-06-10T14:20:04.681592Z"
    }
   },
   "outputs": [],
   "source": [
    "import vaex.ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform features: PCA of the pick-up and drop-off locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:20:13.117925Z",
     "start_time": "2020-06-10T14:20:10.886829Z"
    }
   },
   "outputs": [],
   "source": [
    "# PCA of the pickup and dropoff locations - helps to \"straighten out\" the coordinates\n",
    "\n",
    "# pickup transformations\n",
    "pca_pu = vaex.ml.PCA(features=['pickup_longitude', 'pickup_latitude'], n_components=2, progress=True)\n",
    "df_train = pca_pu.fit_transform(df_train)\n",
    "\n",
    "# dropoff transformations\n",
    "pca_do = vaex.ml.PCA(features=['dropoff_longitude', 'dropoff_latitude'], n_components=2, progress=True)\n",
    "df_train = pca_do.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the new columns (PCA transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:21:19.853570Z",
     "start_time": "2020-06-10T14:21:18.515897Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:21:35.027085Z",
     "start_time": "2020-06-10T14:21:33.975670Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('pickup - original')\n",
    "df_train.plot(df_train.pickup_longitude, df_train.pickup_latitude,\n",
    "           colormap='plasma', f='log1p', shape=256, colorbar=False)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('pickup - PCA transformed')\n",
    "df_train.plot(df_train.PCA_0, df_train.PCA_1,\n",
    "           colormap='plasma', f='log1p', shape=256, colorbar=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling temporal (cyclical) features\n",
    "\n",
    "- Assume the temporal feature is the θ coordinate of a unit circle in polar coordinates. Conver it to Cartesian (x,y) coordinates. This preserves the continuity (12 o'clock is close to 1 o'clock)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:21:54.563843Z",
     "start_time": "2020-06-10T14:21:54.549171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Time\n",
    "cycl_transform_time = vaex.ml.CycleTransformer(features=['pickup_time'], n=24)\n",
    "df_train = cycl_transform_time.fit_transform(df_train)\n",
    "\n",
    "# Day\n",
    "cycl_transform_day = vaex.ml.CycleTransformer(features=['pickup_day'], n=7)\n",
    "df_train = cycl_transform_day.fit_transform(df_train)\n",
    "\n",
    "# Direction angle\n",
    "cycl_transform_angle = vaex.ml.CycleTransformer(features=['direction_angle'], n=360)\n",
    "df_train = cycl_transform_angle.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:21:56.944419Z",
     "start_time": "2020-06-10T14:21:55.262804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's see how the transformed date would look like\n",
    "df_train.plot(x='pickup_time_x', y='pickup_time_y',\n",
    "              shape=128, limits=[-1, 1],\n",
    "              figsize=(5, 5),\n",
    "              colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:22:06.757116Z",
     "start_time": "2020-06-10T14:22:05.356658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard scaling of numerical features\n",
    "standard_scaler = vaex.ml.StandardScaler(features=['arc_distance'])\n",
    "df_train = standard_scaler.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:22:18.129297Z",
     "start_time": "2020-06-10T14:22:17.784398Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select all the features to be used for training the model\n",
    "features = df_train.get_column_names(regex='PCA*') + \\\n",
    "           df_train.get_column_names(regex='standard_scaled_*') + \\\n",
    "           df_train.get_column_names(regex='.*_x') + \\\n",
    "           df_train.get_column_names(regex='.*_y') + \\\n",
    "           ['pickup_is_weekend']\n",
    "\n",
    "# Preview the features\n",
    "df_train.head(10)[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:22:33.476076Z",
     "start_time": "2020-06-10T14:22:33.473745Z"
    }
   },
   "outputs": [],
   "source": [
    "target = 'trip_duration_min'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:23:02.032781Z",
     "start_time": "2020-06-10T14:22:36.995416Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from vaex.ml.sklearn import IncrementalPredictor\n",
    "\n",
    "# Define the base model\n",
    "model = SGDRegressor(learning_rate='constant', eta0=0.0001)\n",
    "\n",
    "# The Vaex incremental model wrapper\n",
    "vaex_model = IncrementalPredictor(features=features,\n",
    "                                  target=target,\n",
    "                                  model=model,\n",
    "                                  batch_size=11_000_000, \n",
    "                                  num_epochs=1, \n",
    "                                  shuffle=False, \n",
    "                                  prediction_name='predicted_duration_min')\n",
    "\n",
    "# Fit the model\n",
    "vaex_model.fit(df=df_train, progress='widget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:23:35.034598Z",
     "start_time": "2020-06-10T14:23:27.929503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard in-memory predict\n",
    "vaex_model.predict(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaex makes models transformers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:23:49.896006Z",
     "start_time": "2020-06-10T14:23:49.540988Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = vaex_model.transform(df_train)\n",
    "# See a portion of the predictions\n",
    "df_train.head(5)['trip_duration_min', 'predicted_duration_min']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is an expression! Opprotunities for post-processing, ensembles etc..\n",
    "\n",
    "Values lower than 3 minutes are set to 3; values higher than 25 minutes are set to 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:24:28.898480Z",
     "start_time": "2020-06-10T14:24:28.894796Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['pred_final'] = df_train.predicted_duration_min.clip(3, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But.. what about the test set?!\n",
    "\n",
    "### State transfer (a.k.a the `vaex` automatic pipeline)\n",
    "\n",
    "The operations done on the data are recorded in the `state` of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:24:33.442317Z",
     "start_time": "2020-06-10T14:24:33.434238Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.state_get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the state to disk (serializes the operations and model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:24:36.204653Z",
     "start_time": "2020-06-10T14:24:36.200842Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.state_write('./taxi_ml_state.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
